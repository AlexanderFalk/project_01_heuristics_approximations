\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage{natbib}
\usepackage{url}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subfig}
\graphicspath{{../images/}}
\usepackage{parskip}
\usepackage{fancyhdr}
\usepackage{textgreek}
\usepackage{vmargin}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\newcommand{\var}{\texttt}
\usepackage[toc,page]{appendix}

\setmarginsrb{3 cm}{2.5 cm}{3 cm}{2.5 cm}{1 cm}{1.5 cm}{1 cm}{1.5 cm}

\title{Heuristics \& Approximations Algorithms}								% Title
\author{Alexander \& Narongrit}								% Author
\date{27 May 2019}											% Date

\makeatletter
\let\thetitle\@title
\let\theauthor\@author
\let\thedate\@date
\makeatother

\pagestyle{fancy}
\fancyhf{}
\rhead{\theauthor}
\lhead{\thetitle}
\cfoot{\thepage}

\makeatletter
\let\OldStatex\Statex
\renewcommand{\Statex}[1][3]{%
  \setlength\@tempdima{\algorithmicindent}%
  \OldStatex\hskip\dimexpr#1\@tempdima\relax}
\makeatother

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{titlepage}
	\centering
    \vspace*{0.5 cm}
    \includegraphics[scale = 0.5]{SDU_logo.png}\\[1.0 cm]	% University Logo
    \textsc{\LARGE University of Southern Denmark}\\[2.0 cm]	% University Name
	\textsc{\Large DM852}\\[0.5 cm]				% Course Code
	\rule{\linewidth}{0.2 mm} \\[0.4 cm]
	{ \huge \bfseries \thetitle}\\
	\rule{\linewidth}{0.2 mm} \\[1.5 cm]
	
	\begin{minipage}{0.4\textwidth}
		\begin{flushleft} \large
			\emph{Submitted To:}\\
			Marco Chiarandini\\
            Lene Monrad Favrholdt \\
			IMADA \\
			Mathematics \& Computer Science Department \\
			\end{flushleft}
			\end{minipage}~
			\begin{minipage}{0.4\textwidth}
            
			\begin{flushright} \large
			\emph{Submitted By :} \\
			Alexander Lerche Falk\\
            Narongrit Unwerawattana\\
            Spring - Master of Computer Science\\
		\end{flushright}
        
	\end{minipage}\\[2 cm]
	
	
    
    
    
    
	
\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

This project shows metaheuristic algorithms, resolving the Capacitated Vehicle Routing Problem (CVRP). The difference between metaheuristics and heuristics is in 
the solution part. For heuristics, you are trying your best to find a solution, even though it is not optimal. The algorithm is adapted to the problem
in such a greedy approach, it can get stuck in a local optimum. This is fine since it is the idea of heuristics: "just solve the problem". 
\newline
Metaheuristics are less greedy and tend to be more problem independent. They accept temporary solutions and allow "bad" steps as an attempt to get
a better solution. You have a local- and global optimum to keep track of the best solution found. You can say metaheuristics are exploiting
heuristics to avoid getting trapped. 
\newline
In this metaheuristics implementation project, we have chosen to implement two algorithms for CVRP: Simulated Annealing (SA) and Ant Colony Optimization (ACO). 
The SA algorithm is the one we have uploaded for electronic submission at http://valkyria.imada.sdu.dk/D0App/. The ACO algorithm is implemented but does not perform well.
We will compare the algorithms with our previous heuristic / local search project and lastly, show our results of computation for our two algorithms.

\hspace{1 cm}--- Alexander \& Narongrit

\newpage

\section{Simulated Annealing} 


The Simulated Annealing (SA) algorithm is inspired from the annealing process in metal, where you are altering the physical state of the metal 
by heating and cooling it. The inspiration can be used in computer science as well. We can use the algorithm on CVRP by starting off by generating a solution 
to the problem and not "care" about the initial solutions. The better steps we are taking, and better solutions we are finding, the more careful we are going to be in finding 
a solution. In the beginning we allow random and bad steps to be performed, while later, we make better calculations.
\newline
We have developed an algorithm to solve CVRP using Simulated Annealing technique by relating CVRP with existed problems i.e. Bin packing problem and Knapsack problem. Using this approach, we can guarantee maximum amount of vehicles necessary required with approximation analysis on bin packing hueristic algorithm. In this demonstration, we use well studied  algorithm First-Fit-Decreasing which is guaranteed to use no more than $\frac{11}{9}\textsc{OPT} + 1$ number of required vehicles\cite{FFD}. With combination of simple Traveling Salesman Problem's local search algorithm, 2-opt, we are able create the initial feasible solution. Next step of Simulated Annealing involved creating new feasible solution by altering current solution. Which in CVRP case, is to perform points exchange action between routes. In order to allow as much possibility of exchanges as it could without breaking capacity constrain, we choose simple algorithm to find exchanges possibility based on Knapsack problem. Our implementation of acceptance criterion is based on Metropolis condition which accept new solution by using probability $p = \exp[−\frac{new\_cost − best\_cost}{temp}]$, this leads to $p = 1$ when $new\_cost < best\_cost$ otherwise $p = [0,1)$. We use geometric cooling scheme in order to update temperature every iteration the algorithm accepts new solution by multiply temperature variables with $alpha$ where  $alpha=(0,1)$. This makes $p$ have lower probability to accept worsen solution after later iteration. All algorithms is described below in this paper.

\begin{algorithm}[!h]
    \footnotesize
    \caption{Simulated annealing with First-Fit-Decreasing and Knapsack combination}
    \label{alg:alg_sa}
    
    \begin{algorithmic}[1]
        \Require{$customers$: List of customer coordinate with it's capacity}
        \Require{$max\_cap$: Maximum capacity for each route}
        \Require{$depot$: Depot point}
        
        \Require{$is\_accept(best\_cost, cost, temp)$: an acceptance criterion function returns boolean based on Metopolis condition}
        
        \Function{simulated\_annealing\_ffd}{{$temp, alpha, no\_improve\_limits$}}
        \State $routes \gets \textsc{cvrp\_first\_fit\_decreasing}(customers,depot)$
        \State $best\_cost \gets$ total cost of $routes$
        \State $best\_routes \gets routes$
        \State $current\_cost \gets best\_cost$
        \State $current\_routes \gets routes$
        \State $curr\_no\_improve\_trying \gets 0$
        \While{True}
        \If{$curr\_no\_improve\_trying == no\_improve\_limits$}
        break
        \EndIf
        \State $new\_routes \gets \textsc{neighbors\_selection}(current\_routes)$
        
        \State $new\_cost \gets$ cost of $new\_routes$
        
        \If{$is\_accept(best\_cost, new\_cost, temp)$}
        \State $temp \gets temp * alpha$
        \State $curr\_no\_improve\_trying \gets 0$
        \State update $current\_routes$ with new routes
        \If{$new\_cost < best\_cost$}
        \State update best\_cost and best\_routes with new routes
        \EndIf
        \Else
        \State $curr\_no\_improve\_trying \gets curr\_no\_improve\_trying + 1$
        \EndIf
        \EndWhile
        \Return $best\_routes$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[!h]
    \footnotesize
    \caption{First-Fit-Decreasing for CVRP}
    \label{alg:alg_ffd}
    
    \begin{algorithmic}[1]
        \Require{$customers$: List of customer coordinate with it's capacity}
        \Require{$tsp\_local\_search(route)$: performs traveling salesman local search and returns improved route}
        \Require{$max\_cap$: Maximum capacity for each route}
        \Require{$depot$: Depot point}
        \Require{$route\_cost(route)$: returns capacity of route}
        
        \Ensure{$routes$: solution routes}
        \Function{cvrp\_first\_fit\_decreasing}{{$customers$}}
        \State $sorted\_capacity\_points \gets$ sort customer points by it's capacity
        \State $routes \gets []$
        \State add new array with $depot$ to $routes$ to create new route
        \ForAll{$point$ in $sorted\_capacity\_points$}
        \State $is\_fit \gets False$
        \ForAll{$route$ in $routes$}
        \If{$route\_cost(route) + point.capacity \leq max\_cap$}
        \State add $point$ to $route$
        \State $is\_fit \gets True$
        \State break
        \EndIf
        \EndFor
        
        \If{$!is\_fit$}
        \State add new route with $depot$ and $point$ to $routes$
        \EndIf
        \EndFor
        
        \ForAll{$route$ in $routes$}
        \State $route \gets tsp\_local\_search(route)$
        \EndFor
        \Return $routes$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[!h]
    \footnotesize
    \caption{Neighbours selection for SA}
    \label{alg:alg_ffd}
    \begin{algorithmic}[1]
        \Require{$routes$: list of routes in solution contains customer coordinate and it's capacity required}
        \Require{$max\_cap$: Maximum capacity for each route}
        
        \Require{$route\_cap(route)$: returns capacity of $route$}
        \Require{$tsp\_local\_search(route)$: performs traveling salesman local search and returns improved route}
        
        \Ensure{$new\_routes$: new solution routes}
        
        \Function{neighbor\_selection}{{$routes$}}
        
        \Repeat
        \State $origin\_route\_id, target\_route\_id \gets$ randomly pick 2 distinct index of $routes$
        \State $origin\_route\_point \gets$ randomly pick element from $route[origin\_route\_id]$
        
        % \State $upper\_bound, lower\_bound \gets$ maximum and minimum capacity such that solution still feasible after exchange action
        
        \State $upper\_bound \gets max\_cap - (route\_cap(routes[origin\_route\_id] - origin\_route\_point.capacity))$
        
        \State $lower\_bound \gets route\_cap(routes[target\_route\_id]) - (max\_cap - origin\_route\_point.capacity)$
        
        \State $target\_neighbor\_set \gets \textsc{knapsack\_combination}($
            \Statex $route[target\_route\_id], lower\_bound, upper\_bound)$
        
        \Until{$len(target\_neighbor\_set) > 0$}
        
        \State $target\_neighbor \gets$ randomly pick an element from $target\_neighbor\_set$
        
        \State $new\_route\_origin, new\_route\_target \gets$ exchange neighbors between two route and assign to new variables
        
        \State $new\_route\_origin \gets tsp\_local\_search(new\_route\_origin)$
        \State $new\_route\_target \gets tsp\_local\_search(new\_route\_target)$
        
        \State $new\_routes \gets$ $routes$ where $route[origin\_route\_id]$ and $route[target\_route\_id]$ replaced by new routes
        \State \Return $new\_routes$
        \EndFunction
        
    \end{algorithmic}
\end{algorithm}


\begin{algorithm}[!h]
    \footnotesize
    \caption{Knapsack Combination}
    \label{alg:alg_knapsackcom}
    
    \begin{algorithmic}[1]
        \Require{$customers$: List of customer coordinate with it's capacity}
        \Require{$max\_cap$: Maximum capacity for each route}
        \Require{$depot$: Depot point}
        \Require{$max\_points\_amt$: Number of maximum combination points}
        \Require{$route\_cap(route)$: returns capacity of $route$}
        
        \Ensure{$combination\_set$: set of candidates combination of points in $route$}
        \Function{knapsack\_combination}{$route, lower\_bound, upper\_bound$}
        
        \State $points$
        \If{$len(route) < max\_points\_amt$}
        \State $points \gets$ randomly pick $len(route)$ points from $route$ but $depot$
        \Else
        \State $points \gets$ randomly pick $max\_points\_amt$ points from $route$ but $depot$
        \EndIf
        \State $combination\_set \gets$ []
        
        \Function{knapsack\_combination\_recur}{{$current\_point\_id, current\_capacity, knapsack$}}
        \If{$current\_point\_id == len(points)$}
        \If{$route\_cap(knapsack) > lower\_bound$}
        \State add knapsack to $combination\_set$
        \EndIf
        \EndIf
        \State $knapsack\_combination\_recur($
            \Statex $current\_point\_id + 1, current\_capacity, knapsack)$
        
        \If{$current\_cap + points[current\_point\_id] \leq max\_cap$}
        \State add $points[current\_point\_id]$ to $knapsack$
        \State $current\_cap \gets points[current\_point\_id].capacity$
        \State $knapsack\_combination\_recur($
            \Statex $current\_point\_id + 1, current\_capacity, knapsack)$
        
        \EndIf
        \EndFunction
        \State $knapsack\_combination(0,0,[])$
        \State \Return $combination\_set$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

\newpage
\subsection{Complexity and Analysis}

By relating CVRP to other existed problem, we are able to come up with a simple algorithm and use existed technique, Simulated Annealing, to improve the solution. We first analyzing our algorithm to construct our initial routes. Using $\textsc{First-Fit-Decreasing}$ to assign group customer points for a vehicle only have runtime complexity of $O(nlogn)$ but in order to decide customer point sequences for each route, we rely on local search algorithm for traveling salesman problem which dominates runtime complexity of our bin packing algorithm. Using simple 2-opt local search algorithm arrange customer point sequences for each vehicle route yields runtime complexity of $O(n^2)$.

Another key task of Simulated Annealing is the neighbor selection procedure. Our attempt is to find largest possibility of exchanging customer point between routes. The problem is risen when given one customer point chosen by uniform distribution probability, how can we decide other candidate to make exchange action and such candidate should not leads to infeasible solution. Introducing a simple algorithm to find possibility of packing customer point into one set based on brute force algorithm for Knapsack problem, which explore for every customer points either to include in neighbor exchange candidate or not, allows us to find a list of feasible candidates to make exchange between routes. But tradeoff of this algorithm is the runtime complexity, which is $O(2^n)$ where $n$ is number of customer points in candidate route. In order to keep runtime of each Simulated Annealing iteration footnotesize, we introduce a user-defined variable $max\_points\_amt$ which an algorithm will use to choose number of customer points in candidate route and proceed the algorithm. This indeed reduces the number of possibility on selecting exchange neighbors candidates but in an instance where it consist of many footnotesize capacity point, without limiting such customer point might leads to long runtime for each neighbor selection process. We conclude that for each iteration of our Simulated Annealing the runtime complexity is in $O(2^n)$ where $n$ is maximum number of points allowed to be exchange.

\begin{figure}[!h]
	\caption{Illustration of the cost per each acceptance iteration of Simulated Annealing for 3 Simulated Annealing schedule on instance A-n32-k05}
	\centering
	\includegraphics[width=0.9\textwidth]{A-n32-k05-sa-cost.png}
	\label{fig:A-n32-k05-sa-cost}
\end{figure}

\include{perf_table}

\newpage
\section{Ant Colony Optimization}
The Ant Colony Optimization (ACO) algorithm comes from the evolutionary algorithms, where computer science meets nature. In this algorithm, 
we have led us to be inspired by how ants find food in the nature. They are starting by spreading out in some area, randomly. When they seem to find trails, 
which could indicate to be good trails to find food, they leave pheromone behind them. The pheromone is used by other ants to determine their probability of taking 
a trail. If they are standing in a cross-section and they have to choose, they are taking the path with the highest pheromone. 
At some point in their exploration to find the best trail to obtain food, all the ants are using the same trails to get food and get back safe home. 
\newline
We can apply the logic of the ants in the CVRP as well. By letting the instance \- the space of which the requests are "plotted" \- be the area to find a solution, 
we can start by sending one "ant" out to a random point. This is going to be our current point. From this point, we are going to calculate every probability of moving to the next point \- the one with the highest "score". 
We can calculate the probability of moving by the doing the following: 
\newline
First we establish the initial pheromone levels from all the points to every counter other point: \\
This is stored in matrix: 

\[
M = \begin{bmatrix}
    0 & 0.50 & 0.20           \\[0.3em]
    0.125 & 0           & 0.60 \\[0.3em]
    1.20 & 0.355 & 0
\end{bmatrix}
\]
We also keep track of the points being visited, so we do not keep visiting the same nodes. Then we start calculating a score for each point from the current point.
We do this by the formula: \\


\begin{equation}
score = \alpha^{\frac{1.0}{distance(i,j)}^\beta}
\end{equation}

The \textalpha  value defines the importance of the pheromone level, where the \textbeta  value defines the importance of the distance between two points. After finding the score for 
each point from the current point, we can calculate the probability by dividing the score by the summation of all scores: \\

\begin{equation}
prob = \frac{score}{\displaystyle\sum_{i=1}^{n} score_i}
\end{equation}

Where \textbf{n} is equivalent to the number of points. We can now append additional pheromone to the trail from the current point to the next point, 
by dividing: 
\begin{equation}
    newpheromone = \frac{1}{distance(i, j)}
\end{equation}

Now we can continue with our usual CVRP properties, where we ensure the capacity of the vehicle is not breached. We continue finding points with the above 
algorithm. \\
After the algorithm has found a solution, we are going to run it again, with the same pheromone matrix, but with updated values, where every pheromone in the trails evaporates a footnotesize percentage before each iteration. 
 A timer is being set, which controls for how long the algorithm runs. \\
In Figure \ref{fig:acowhiteboard} a drawing has been created to visualize the idea of the algorithm: \\

\begin{figure}[h]
	\caption{Illustration of the ACO algorithm, showing how it can be used, and how it process next moves}
	\centering
	\includegraphics[width=0.9\textwidth]{ACO_Whiteboard.jpg}
	\label{fig:acowhiteboard}
\end{figure}

The complexity of the algorithm is $O(n)$ after initializing the pheromone matrix, due to the amount of checks from the current point 
it has to perform, which is \textit{n}

\newpage
\begin{algorithm}[!ht]
    
    \footnotesize

    \caption{Metaheuristic - Ant Colony Optimization}
    \begin{algorithmic}[1]
        \State $\var{max\_iteration} \gets \text{number of iteration}$
        \State $\var{i} \gets \text{0}$
        \State $\var{global\_best\_route} \gets \text{empty route/array}$
        \While{$\var{i} < \var{max\_iteration}$ or a time limit is not reached}
            \State $\var{local\_best\_route} \gets \text{empty route/array}$
            \State $\var{current\_route} \gets \text{empty route/array}$
            \State $\var{capacity} \gets 0$
            \State $\var{alpha} \gets \text{A random number}$
            \State $\var{beta} \gets \text{A random number greater than alpha}$
            \State $\var{evaporation} \gets \text{Some footnotesize number}$
            \State $\var{pheromone\_matrix} \gets \text{Contains every pheromone for each pair}$
            \State $\var{sum\_of\_all\_pheromone} \gets \text{The summation of the pheromone\_matrix}$
            \State $\var{i++}$
            \For{${first\_point} \gets 0$ to $\text{length of data}$}
                \For{${second\_point} \gets 0$ to $\text{length of data}$}
                    \If{${first\_point} \neq {second\_point}$}
                        \State $\var{pheromone\_matrix(first, second)} \gets 1 / distance$
                        \State $\var{sum\_of\_all\_pheromone} \gets \text{append calculated pheromone to the sum}$
                    \EndIf
                \EndFor
            \EndFor

            \State Pick a random point for the list of points and mark it as visited
            \State Append it to the routes
            \State Keep storage of the previous score

            \While{${point} \neq \text{visited in list}$}
                \For{key in \text{pheromone\_matrix}}
                    \State Calculate and store the Score-equation
                    \State Calculate and store the Probability-equation
                    \If{the new score < previous score \&\& key is not visited}
                        \State Set the key of the request to the point moved to

                    \EndIf
                \EndFor

                \State Append Newpheromone-equation to the trail of the point moved to

                \If{Capacity of picked point $\leq$ Capacity Constraint}
                    \State Capacity capacity of request
                    \State Append picked point to \var{current\_route}
                    \State Mark picked point as visited
                    \State Set picked point to the current point
                    \State Set previous score to 0

                \Else
                    \State Reset \var{current\_route} and append picked point to new route
                    \State Mark point as visited
                    \State{$\var{capacity} \gets \text{capacity\ of\ picked\ point}$}
                    \State Set previous score to 0
                \EndIf
            \EndWhile
            \If{\var{current\_route} is better than \var{local\_best\_route}}
                \State $\var{local\_best\_route} \gets \var{current\_route}$    
            \EndIf

            \If{\var{local\_best\_route} is better than \var{global\_best\_route}}
                \State $\var{global\_best\_route} \gets \var{local\_best\_route}$  
            \EndIf

            \State loop through \var{pheromone\_matrix} and evaporate every pheromone trail by a footnotesize percentage
        \EndWhile
    \end{algorithmic}
\end{algorithm}

\newpage
\section{Discussion}


Metaheuristics takes longer to execute, since they are not stopping until certain criteria is fulfilled. This criteria can be hard to reach and therefore, 
the algorithm can be running forever. In our two metaheuristic algorithms, the stopping criteria is the timespan of the running process. When the algorithms have been running for the set time, the process\' is stopped. \\
Our Simulated Annealing algorithm does run for a long time with an exponential complexity. Looking at our Table~\ref{table:cost}, we comparing solution produced by our first project cluster heuristic - picks furthest point from the depot and uses the nearest addition heuristic approach to generate routes in clusters to form a tour - with Simulated Annealing metaheuristic algorithm. For Simulated Annealing, we earn benefit from using $\textsc{First-Fit-Decreasing}$ since our required vehicles for Simulated Annealing solution is less than our previous algorithm in most case but some of Golden instances which caused by the distribution of customer point. Cost-wise, our the heuristic algorithm still out perform Simulated Annealing in most cases. We concluded, allowing more possibilities on developing neighbor selection, is not benefitting the the total cost much. An idea to improve the neighbor selection is to create a smarter algorithm to pick a neighbor, such as selecting and exchanging neighbors based on it's proximity. This could allow the Simulated Annealing to be better in obtaining a local optimum earlier in each iteration. 
Since we did not get the ACO algorithm to work properly, the only comparison we were able to make, was between the first instance: A-n32-k05. Here, the ACO was finding a cost around 1800-1900, where the SA - from Table~\ref{table:cost} - found costs at 980. This makes a great win for the SA in our case.

\section{Contribution}
It is always a pleasure to work together. We are both enthusiastic about the work and challenges ourselves with stuff, we might not be able to do, but we learn a lot. 
The workload has been splitted between us as close to 50/50 as we could and our communication has been friendly and nice. 

Narongrit Unwerawattana
\begin{itemize}
	\item Development of Simulated Annealing
	\item Performance Table compared to our Heuristic algorithm
	\item Performance Graph
\end{itemize}
Alexander Lerche Falk
\begin{itemize}
	\item Development of Ant Colony Optimization
\end{itemize}
both
\begin{itemize}
	\item Writing report
\end{itemize}

\bibliographystyle{plain}
\bibliography{references}

\end{document}